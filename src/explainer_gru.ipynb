{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from argparse import Namespace\n",
    "from transformers.optimization import AdamW\n",
    "from evaluator import Evaluator\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from modeling_gru import GRU_TS_Explained\n",
    "\n",
    "from timeshap.explainer import local_report, global_report, calc_local_report, plot_local_report,calc_global_explanations,plot_global_report\n",
    "from timeshap.wrappers import TorchModelWrapper\n",
    "from utils import parse_args,set_all_seeds,set_output_dir,Logger, save_results\n",
    "from dataset import Dataset\n",
    "from timeshap.utils import calc_avg_event\n",
    "from timeshap.utils import get_avg_score_with_avg_event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16/10/2024 14:13:00 >> Namespace(dataset='mimic_iii', train_frac=0.7, run='1o10', model_type='gru', max_obs=880, hid_dim=32, num_layers=2, num_heads=4, dropout=0.2, attention_dropout=0.2, kernel_size=4, r=24, M=12, max_timesteps=880, num_ts_feat=51, num_demo_feat=3, hours_look_ahead=24, ref_points=24, pretrain=0, output_dir='../outputs/mimic_iii/gru,hid_dim:32,dropout:0.2,lr:0.0005,gradient_accumulation_steps:8,max_epochs:1|train_frac:0.7|run:1o10', output_dir_prefix='', seed=2024, max_epochs=1, patience=10, lr=0.0005, train_batch_size=16, gradient_accumulation_steps=8, eval_batch_size=16, print_train_loss_every=100, validate_after=-1, validate_every=None, load_ckpt_path=None, logger=<utils.Logger object at 0x2b5519720>)\n",
      "\n",
      "16/10/2024 14:13:02 >> Preparing dataset mimic_iii\n",
      "16/10/2024 14:13:02 >> Removing variables not in training set: ['.3% normal Saline']\n",
      "16/10/2024 14:13:03 >> # train, val, test TS: [3918, 1120, 800]\n",
      "16/10/2024 14:13:03 >> pos class weight: 3.934508816120907\n",
      "16/10/2024 14:13:03 >> % pos class in train, val, test splits: [0.2026544155181215, 0.19732142857142856, 0.20625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12199it [00:00, 1833655.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/10/2024 14:13:03 >> # intervals: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "941654it [00:00, 1737845.85it/s]\n"
     ]
    }
   ],
   "source": [
    "parser = parse_args(model_type = 'gru', hid_dim =32,dropout = 0.2, lr = 0.0005, max_epochs = 1, gradient_accumulation_steps = 8)\n",
    "args, _ = parser.parse_known_args()\n",
    "set_all_seeds(args.seed+int(args.run.split('o')[0]))\n",
    "set_output_dir(args)\n",
    "args.logger = Logger(args.output_dir, 'log.txt')\n",
    "args.logger.write('\\n'+str(args))\n",
    "dataset = Dataset(args)\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos x data shape:  (1, 24, 156)\n"
     ]
    }
   ],
   "source": [
    "d_ts = dataset.X\n",
    "d_demo = dataset.demo\n",
    "demo_expanded = np.expand_dims(d_demo, axis=1)\n",
    "demo_tiled = np.tile(demo_expanded, (1, 24, 1))\n",
    "d_all = np.concatenate((d_ts, demo_tiled), axis=2)\n",
    "\n",
    "num_samples, num_timestamps, num_features = d_all.shape\n",
    "\n",
    "sample_ids = np.repeat(np.arange(num_samples), num_timestamps)\n",
    "timestamps = np.tile(np.arange(num_timestamps), num_samples)\n",
    "\n",
    "# Flatten the data\n",
    "flattened_data = d_all.reshape(num_samples * num_timestamps, num_features)\n",
    "\n",
    "# Combine into a DataFrame\n",
    "d_all_transformed = pd.DataFrame(flattened_data, columns=[f'feature_{i}' for i in range(num_features)])\n",
    "d_all_transformed['sample_id'] = sample_ids\n",
    "d_all_transformed['timestamp'] = timestamps\n",
    "\n",
    "# Reorder columns to have 'sample_id' and 'timestamp' first\n",
    "columns = ['sample_id', 'timestamp'] + [f'feature_{i}' for i in range(num_features)]\n",
    "d_all_transformed = d_all_transformed[columns]\n",
    "\n",
    "# Rename features\n",
    "variable_names = list(dataset.var_to_ind_mapping.keys())\n",
    "feat_names = [v+'_value' for v in variable_names]\n",
    "feat_names += [v+'_obs' for v in variable_names]\n",
    "feat_names += [v+'_delta' for v in variable_names]\n",
    "feat_names += ['age','gender','height']\n",
    "d_all_transformed.columns = ['sample_id', 'timestamp'] + feat_names\n",
    "\n",
    "train_sample_ids = dataset.splits['train']\n",
    "test_sample_ids = dataset.splits['test']\n",
    "d_train_transformed = d_all_transformed[d_all_transformed['sample_id'].isin(train_sample_ids)]\n",
    "d_test_transformed = d_all_transformed[d_all_transformed['sample_id'].isin(test_sample_ids)]\n",
    "\n",
    "feats_in_scope = [v+'_value' for v in variable_names]\n",
    "average_event = calc_avg_event(d_train_transformed, numerical_feats=feat_names, categorical_feats=[])\n",
    "average_event\n",
    "\n",
    "positive_sequence_id = test_sample_ids[0]\n",
    "pos_x_pd = d_test_transformed[d_test_transformed['sample_id'] == positive_sequence_id]\n",
    "\n",
    "# select model features only\n",
    "pos_x_data = pos_x_pd[feat_names]\n",
    "# convert the instance to numpy so TimeSHAP receives it\n",
    "pos_x_data = np.expand_dims(pos_x_data.to_numpy().copy(), axis=0)\n",
    "print(\"pos x data shape: \", pos_x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16/10/2024 14:13:44 >> Size of training data: 3918\n",
      "\n",
      "16/10/2024 14:13:44 >> No. of training batches per epoch: 244.875\n",
      "\n",
      "16/10/2024 14:13:44 >> Max steps: 244.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16/10/2024 14:13:44 >> Evaluating on split = val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "running forward pass: 100%|██████████| 70/70 [00:00<00:00, 610.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/10/2024 14:13:44 >> Result on val split at train step -1: AUROC: 0.4806245249875427: AUPRC: 0.18891448277186873: MINRP: 0.20521739130434782\n",
      "\n",
      "16/10/2024 14:13:44 >> Evaluating on split = eval_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "running forward pass: 100%|██████████| 125/125 [00:00<00:00, 1171.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/10/2024 14:13:45 >> Result on eval_train split at train step -1: AUROC: 0.46951989845663594: AUPRC: 0.20252150126540075: MINRP: 0.214321482223335\n",
      "\n",
      "16/10/2024 14:13:45 >> Evaluating on split = test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "running forward pass: 100%|██████████| 50/50 [00:00<00:00, 1218.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/10/2024 14:13:45 >> Result on test split at train step -1: AUROC: 0.45888809353376286: AUPRC: 0.18916672688752756: MINRP: 0.20898876404494382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16/10/2024 14:13:45 >> Evaluating on split = val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "running forward pass: 100%|██████████| 70/70 [00:00<00:00, 1245.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/10/2024 14:13:45 >> Result on val split at train step 244: AUROC: 0.5766940642946663: AUPRC: 0.248782793335385: MINRP: 0.26582278481012656\n",
      "\n",
      "16/10/2024 14:13:45 >> Evaluating on split = eval_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "running forward pass: 100%|██████████| 125/125 [00:00<00:00, 1311.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/10/2024 14:13:45 >> Result on eval_train split at train step 244: AUROC: 0.5792579249007158: AUPRC: 0.26009096995161046: MINRP: 0.28738317757009346\n",
      "\n",
      "16/10/2024 14:13:45 >> Evaluating on split = test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "running forward pass: 100%|██████████| 50/50 [00:00<00:00, 1273.27it/s]\n",
      "100%|██████████| 245/245 [00:01<00:00, 211.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/10/2024 14:13:46 >> Result on test split at train step 244: AUROC: 0.5467955141970889: AUPRC: 0.23145497221297126: MINRP: 0.24848484848484848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = GRU_TS_Explained(args)\n",
    "model.to(args.device)\n",
    "results = {'epoch':[],'train_auroc':[],'val_auroc':[],'test_auroc':[]}\n",
    "\n",
    "#training\n",
    "num_train = len(dataset.splits['train'])\n",
    "args.logger.write('\\nSize of training data: ' + str(num_train))\n",
    "num_batches_per_epoch = num_train/args.train_batch_size\n",
    "args.logger.write('\\nNo. of training batches per epoch: '\n",
    "                    +str(num_batches_per_epoch))\n",
    "args.max_steps = int(round(num_batches_per_epoch)*args.max_epochs)\n",
    "args.logger.write('\\nMax steps: ' + str(num_batches_per_epoch))\n",
    "\n",
    "if args.validate_every is None:\n",
    "    args.validate_every = int(np.ceil(num_batches_per_epoch)) #validate after each batch\n",
    "\n",
    "num_steps = 0\n",
    "optimizer = AdamW(filter(lambda p:p.requires_grad, model.parameters()), lr=args.lr)\n",
    "train_bar = tqdm(range(args.max_steps))\n",
    "evaluator = Evaluator(args)\n",
    "\n",
    "#before training, calculate metrics\n",
    "if args.validate_after<0:\n",
    "    res_val = evaluator.evaluate_gru_explained(model, dataset, 'val',  train_step=-1)\n",
    "    res_train = evaluator.evaluate_gru_explained(model, dataset, 'eval_train', train_step=-1)\n",
    "    res_test = evaluator.evaluate_gru_explained(model, dataset, 'test', train_step=-1)\n",
    "    results['epoch'].append(0)\n",
    "    results['train_auroc'].append(res_train['auroc'])\n",
    "    results['val_auroc'].append(res_val['auroc'])\n",
    "    results['test_auroc'].append(res_test['auroc'])\n",
    "\n",
    "#training\n",
    "model.train()\n",
    "for step in train_bar:\n",
    "    data_batch = dataset.get_batch()\n",
    "    data_batch = {k:v.to(args.device) for k,v in data_batch.items()}\n",
    "    tensor_a = data_batch['ts']  # torch.Size([16, 24, 150])\n",
    "    tensor_b = data_batch['demo']      # torch.Size([16, 2])\n",
    "    # Expand tensor_b to match the dimensions of tensor_a (i.e., [16, 24, 2])\n",
    "    tensor_b_expanded = tensor_b.unsqueeze(1).expand(-1, 24, -1)  # torch.Size([16, 24, 2])\n",
    "    # Concatenate tensor_b_expanded along the last dimension with tensor_a\n",
    "    data = torch.cat((tensor_a, tensor_b_expanded), dim=2)  # torch.Size([16, 24, 152])\n",
    "    \n",
    "    pred,logits = model(data)\n",
    "    loss = model.binary_cls_final(logits,data_batch['labels'])\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(),0.3)\n",
    "    if (step+1)%args.gradient_accumulation_steps==0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    num_steps += 1\n",
    "\n",
    "    # run validatation\n",
    "    if (num_steps>=args.validate_after) and (num_steps%args.validate_every==0):\n",
    "        # get metrics on test and validation splits\n",
    "        res_val = evaluator.evaluate_gru_explained(model, dataset, 'val', train_step=step)\n",
    "        res_train = evaluator.evaluate_gru_explained(model, dataset, 'eval_train', train_step=step)\n",
    "        res_test = evaluator.evaluate_gru_explained(model, dataset, 'test', train_step=step)\n",
    "        results['train_auroc'].append(res_train['auroc'])\n",
    "        results['val_auroc'].append(res_val['auroc'])\n",
    "        results['test_auroc'].append(res_test['auroc'])\n",
    "        model.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeshap.explainer import prune_all, pruning_statistics, event_explain_all, feat_explain_all\n",
    "from timeshap.plot import plot_global_event, plot_global_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tolerance</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Pruning</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tolerance  Mean  Std\n",
       "0     0.00001  24.0  NaN\n",
       "1  No Pruning  24.0  NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapped = TorchModelWrapper(model)\n",
    "f_hs = lambda ts, y=None: model_wrapped.predict_last_hs(ts, y)\n",
    "schema = list(d_all_transformed.columns)\n",
    "\n",
    "pruning_dict = {'tol': [0.00001]}\n",
    "prun_indexes = prune_all(f_hs, pos_x_pd, pruning_dict, average_event, feat_names, schema, 'sample_id', 'timestamp')\n",
    "pruning_stats = pruning_statistics(prun_indexes, pruning_dict.get('tol'))\n",
    "pruning_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features = {k:k for k in feat_names}\n",
    "feature_dict = {'path': '/content/drive/My Drive/Colab Notebooks/code/outputs/explainable/feat_gru_2309.csv','rs': [42], 'nsamples': [1600], 'feature_names': feat_names, 'plot_features': plot_features,}\n",
    "\n",
    "feat_data = feat_explain_all(f_hs, d_all_transformed, feature_dict, prun_indexes, average_event, feat_names, schema, 'sample_id', 'timestamp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
